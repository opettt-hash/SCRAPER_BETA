# Endpoint Scraper Beta

Tools ini adalah **Endpoint & API Discovery Scanner** yang dirancang dengan kemampuan deep crawling, API discovery, secret key extraction, dan otomatis xploit

---

# üìä Tabel Dokumen Lengkap

## ‚≠ê Fitur Utama
| Kategori | Deskripsi |
|---------|-----------|
| **Endpoint Auto Extract** | HTML Parser, JS Parser, JS Recursive Crawler, Dynamic Import Detector, AJAX Interceptor |
| **Secret Key Detector** | Deteksi API Key, JWT, Bearer, Firebase, Stripe, AWS, RapidAPI, x-api-key |
| **Website Scanner** | Sitemap scan, robots.txt parser, admin path enum, API enum, mobile/debug path |
| **Smart Path Expansion** | Generate endpoint: login, register, auth, info, update, delete, dll |
| **Multithreading & Proxy** | ThreadPoolExecutor 200 thread, proxy rotator, retry system, custom user-agent |
| **Output Lengkap** | JSON, CSV, TXT, Postman Collection, summary log |

---

## üîç Endpoint Auto Extract
| Engine | Kemampuan |
|--------|-----------|
| HTML Parser | href, src, form action, link hidden |
| JS Inline Parser | regex + static code –∞–Ω–∞–ª–∏–∑ |
| External JS Crawler | recursive scanning |
| Dynamic Import Detector | `import("...")` |
| AJAX Request Detector | fetch(), axios(), xhr |
| URL Pattern Recognizer | /api, /v1, /admin, /graphql |

---

## üîë Secret Key Detection
| Jenis Key | Contoh | Deteksi |
|-----------|--------|----------|
| Google API Key | `AIza...` | ‚úÖ |
| Firebase Admin Key | `AAAA:xxxxx` | ‚úÖ |
| Stripe Keys | `sk_live`, `pk_live` | ‚úÖ |
| AWS Access Key | `AKIAxxxx` | ‚úÖ |
| JWT Token | `eyJhbGciOi...` | ‚úÖ |
| Bearer Token | `Bearer xxxxx` | ‚úÖ |
| x-api-key | Header Custom | ‚úÖ |

---

## üåê Website & API Scanner
| Fitur | Status |
|--------|--------|
| Multi-depth crawling | ‚úÖ |
| Recursive link discovery | ‚úÖ |
| robots.txt parser | ‚ùáÔ∏è Bisa ignore |
| Sitemap.xml reader | ‚úÖ |
| HEAD/GET validator | ‚úÖ |
| Admin path scan | `/admin`, `/admincp`, `/panel`, `/dashboard` |
| API enumeration | `/api`, `/api/v1`, `/v2`, `/backend`, `/services` |

---

## ‚öôÔ∏è Smart Path Expansion
| Input Path | Output Path (Generated) |
|-------------|--------------------------|
| `/api/v1/user` | `/login`, `/register`, `/auth`, `/info`, `/update`, `/delete` |
| `/auth` | `/auth/login`, `/auth/refresh`, `/auth/verify` |
| `/admin` | `/admin/login`, `/admin/dashboard`, `/admin/config` |

---

## ü§ñ Multithreading + Proxy Rotator
| Fitur | Detail |
|-------|--------|
| Thread | Max 200 |
| Proxy | otomatis rotate |
| Retry | urllib3 + backoff |
| User-Agent rotate | Mobile + Desktop |
| Timeout | 8s default |

---

## üì§ Output Tools
| File | Fungsi |
|------|--------|
| `endpoints_TIMESTAMP.json` | Data lengkap endpoint |
| `endpoints_TIMESTAMP.csv` | Friendly spreadsheet |
| `endpoints_TIMESTAMP.txt` | Raw list |
| `postman_collection_TIMESTAMP.json` | Auto import ke Postman |
| `summary_TIMESTAMP.log` | Ringkasan scan |

---

# üîß Instalasi
```bash
pkg install python git -y
pip install requests bs4 urllib3 rich
```

# ‚ñ∂Ô∏è Cara Pakai (Lengkap)

## üéØ Mode Dasar
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Scan dasar | `python scraper.py --url https://target.com` | Scan cepat tanpa fitur tambahan |
| Scan + simpan otomatis | `python scraper.py --url https://target.com --save` | Output JSON/CSV/TXT otomatis |

---

## üåê Mode Web Scraping
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Crawling multi-depth | `python scraper.py --url https://site.com --deep` | Mengaktifkan scan recursive |
| Atur depth | `python scraper.py --url https://site.com --depth 5` | Depth 1‚Äì10 |
| Scan JS recursive | `python scraper.py --url https://site.com --js-scan` | Memaksa scan semua file JS |

---

## üî• Mode API & Endpoint Scan
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Scan API otomatis | `python scraper.py --url https://site.com --api` | Cari endpoint `/api/*` |
| Scan + generate endpoint | `python scraper.py --url https://site.com --expand` | Smart Path Expansion aktif |
| Scan GraphQL | `python scraper.py --url https://site.com --graphql` | Cari `/graphql` & schema |

---

## üß© Mode Secret Key Detector
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Deteksi semua secret | `python scraper.py --url https://site.com --secrets` | API Key, JWT, AWS, Firebase |
| Deteksi Firebase | `python scraper.py --url https://site.com --firebase` | Firebase config extractor |
| Deteksi AWS Key | `python scraper.py --url https://site.com --aws` | `AKIAxxxx` + SecretKey |

---

## üöÄ Mode Kecepatan (Threading)
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Gunakan 50 thread | `python scraper.py --url https://site.com --threads 50` | Mode cepat |
| Mode full speed | `python scraper.py --url https://site.com --threads 200` | Maximum speed |

---

## üåê Proxy & User-Agent
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Gunakan proxy list | `python scraper.py --url https://site.com --proxy proxy.txt` | Rotasi otomatis |
| Gunakan proxy tunggal | `python scraper.py --url https://site.com --proxy http://127.0.0.1:8080` | Proxy manual |
| Random UA | `python scraper.py --url https://site.com --random-ua` | Mobile + Desktop mix |
| Set custom UA | `python scraper.py --url https://site.com --ua "Mozilla/5.0"` | Manual UA |

---

## üõ°Ô∏è Filter & Rules
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Whitelist path | `python scraper.py --url https://site.com --allow api,auth,user` | Hanya scan folder tertentu |
| Blacklist path | `python scraper.py --url https://site.com --deny admin,debug,static` | Skip folder tertentu |
| Ignore robots.txt | `python scraper.py --url https://site.com --ignore-robots` | Scan tanpa dibatasi |

---

## üì§ Output & Export
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Export Postman | `python scraper.py --url https://site.com --postman` | Auto generate `.postman.json` |
| Export ke folder lain | `python scraper.py --url https://site.com --output results/` | Custom output folder |
| Simpan JSON | `python scraper.py --url https://site.com --json` | Export JSON saja |
| Simpan CSV | `python scraper.py --url https://site.com --csv` | Export CSV saja |
| Simpan TXT | `python scraper.py --url https://site.com --txt` | Export list TXT |

---

## ‚öôÔ∏è Mode Debug & Testing
| Fungsi | Command | Keterangan |
|--------|---------|-------------|
| Mode debug | `python scraper.py --url https://site.com --debug` | Menampilkan log internal |
| Cek status endpoint | `python scraper.py --url https://site.com --check` | HTTP status checker |
| Print semua JS file | `python scraper.py --url https://site.com --list-js` | Debug resource |

---

## üß™ Contoh Kombinasi Paling Laris
| Tujuan | Command |
|--------|---------|
| Deep scan + secret + postman + thread 100 | `python scraper.py --url https://target.com --deep --secrets --postman --threads 100` |
| Full API scan + expand | `python scraper.py --url https://target.com --api --expand` |
| Proxy + deep JS crawler | `python scraper.py --url https://target.com --proxy proxy.txt --js-scan --deep` |
| Crawl + bypass robots | `python scraper.py --url https://target.com --ignore-robots --deep` |

---

# üí° Tips
| Tip | Manfaat |
|------|---------|
| Gunakan proxy list minimal 50 | Supaya tidak kena rate‚Äëlimit |
| Aktifkan --random-ua | Menghindari blokir bot |
| Gunakan --expand | Munculin endpoint tersembunyi |
| Gunakan --secrets | Buka peluang temukan API KEY |

---
